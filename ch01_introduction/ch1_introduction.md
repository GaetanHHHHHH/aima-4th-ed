# Chapter 1: Introduction

---

# **1.1   What is AI**

- Pens√©es vs comportements
- Mod√©lisation d‚Äôhumains vs atteindre le meilleur r√©sultat

## **Acting humanly: Turing test**

- Il est au final plus important de comprendre les principes sous tenants √† l‚Äôintelligence (all√©gorie du vol o√π on a arr√™t√© de copier les oiseaux)

## **Thinking humanly: Cognitive modeling approach**

- *cognitive science*
    - mix entre les mod√®les informatiques originaires de l‚ÄôIA et des techniques exp√©rimentales originaires de la psychologie

## **Thinking rationally: The ‚Äúlaws of thought‚Äù approach**

- Besoin d‚Äôune th√©orie de l‚Äôaction rationnelle pour g√©n√©rer un comportement intelligent

## **Acting rationally: The rational agent approach**

- Laws of thoughts: faire des d√©ductions correctes
- Agir rationnellement :
    - knowledge representation
    - reasoning
    - ‚áí bonnes d√©cisions
- *Rational-agent approach* vs *laws of thoughts*:
    - plus g√©n√©ral (faire de bonnes d√©ductions n‚Äôest qu‚Äôune fa√ßon d‚Äô√™tre rationnel)
    - plus simple √† d√©velopper scientifiquement

<aside>
üí° **Standard model of AI**: *AI has focused on the study and construction of agents that do the right thing.*

</aside>

- Dans un monde complexe, c‚Äôest impossible de toujours prendre la meilleure d√©cision (*limited rationality*)

## **Beneficial machines**

- *Standard model*: Pas id√©al car on ne peut/veut pas toujours donner un objectif parfaitement d√©fini √† une machine
    - difficile √† faire dans le vrai monde
- *Value alignment problem*: Arriver √† faire correspondre nos vraies pr√©f√©rences √† un objectif programmable
- On souhaite que les machines soient *provably beneficial* aux humains

# **1.2   The Foundations of Artificial Intelligence**

## **Philosophy**

- Les connaissances sont la base de l‚Äôaction, et sont enregistr√©es dans une forme de langage interne qui permet de choisir une action adapt√©e

## **Mathematics**

- Logique formelle ‚Üí [logique de premier ordre](https://en.wikipedia.org/wiki/First-order_logic)
- G√©n√©raliser la logique aux situations d‚Äôinformation incertaine ‚Üí Th√©orie des probabilit√©s
- Ajout de la math√©matisation de la [*computation*](https://en.wikipedia.org/wiki/Computation) √† la logique et aux probabilit√©s
- [Th√©or√®me de l‚Äôincompl√©tude](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems) (G√∂del, XX√®me)
    - Des limites √† la d√©duction existent
    - Certaines fonctions ne peuvent pas √™tre repr√©sent√©es par un algorithme et donc ne peuvent pas √™tre calcul√©es
- Intractabilit√©:
    - Le temps requit par un probl√®me intractable grandit exponentiellement avec la taille (nombre) des instances

## **Economics**

- Maximum expected value (Arnauld, 1662)
- Maximisation de l‚Äôutilit√© attendue (Bernoulli, 1738)
- Decision theory:
    - Combiner les probabilit√©s et l‚Äôutilit√© pour cr√©er un mod√®le complet et formel de la prise de d√©cision individuelle
- Satisfaction (Simon, 1978 Nobel prize):
    - Prendre des d√©cisions qui sont satisfaisantes et pas optimales

## **Neuroscience**

- Les fonctions cognitives sont le r√©sultat d‚Äôop√©rations √©lectrochimiques

<aside>
üß† *A collection of simple cells can lead to thought, action, and consciousness*
or
*Brains cause minds*

</aside>

- Machines et cerveaux ont des fonctionnements et des performances diff√©rentes
    - Singularit√©: Les ordinateurs atteindront un niveau surhumain

## **Psychology**

- Psychologie cognitive (James, XIX-XX√®me)
- Humains et animaux peuvent √™tre qualifi√©s de *information-processing machines*

## **Computer engineering**

- Cr√©ation d‚Äô*hardware* et de *software* de plus en plus puissants
    - Cr√©ation r√©cente d‚Äôordinateurs sp√©cifiques pour l‚ÄôAI
    - Informatique quantique
    - Am√©liorations logicielles

## **Control theory and cybernetics**

- D√©veloppement de la *control theory* (Wiener, XX√®me)
    - M√©canisme de r√©gulation gr√¢ce √† la minimisation de l‚Äôerreur
- Appareils hom√©ostatiques (1940-52):
    - Utilisation de boucles de r√©troaction
- *Stochastic optimal control*:
    - Maximiser (*ndlr*: minimiser?) une fonction de co√ªt en fonction du temps

## **Linguistics**

- *Computational linguistics* ou *natural langage processing*
    - Compr√©hension du sujet et du contexte, pas de la structure des phrases
- Lien entre *knowledge representation* et linguistique

# **1.3   The History of Artificial Intelligence**

- Histoire longue et complexe, avec beaucoup de hauts (espoirs d√©lirants, investissements, succ√®s) et de bas
- Successions d‚Äôam√©liorations de technologies existantes et de nouvelles innovations

# **1.4   The state of the art**

- L‚ÄôIA s‚Äôest beaucoup am√©lior√©e avec le temps, en m√©thodologie et en th√©orie
- Logique bool√©enne ‚û°Ô∏è raisonnement probabilistique
- Connaissances ‚Äúhardcod√©es‚Äù ‚û°Ô∏è machine learning bas√© sur les donn√©es

‚áí Am√©lioration des performances des syst√®mes et applications √† d‚Äôautres domaines

# **1.5   Risks and benefits of AI**

- Plus les domaines d‚Äôapplication sont larges, plus les risques et cons√©quences √©thiques sont larges
- Apparition potentielle d‚Äôune IA superintelligence et difficile √† contr√¥ler
    - Modification de notre fa√ßon de concevoir l‚ÄôIA

# 1.A   Exercises

1. Define in your own words: (a) intelligence, (b) artificial intelligence, (c) agent, (d) rationality, (e) logical reasoning.
    1. Intelligence is the capacity to creatively solve problems
    2. AI is a field of research that aims at creating programs (agents) that can navigate their environment, make decisions, and perform actions by themselves
    3. An agent is a sum of programs encapsulated in a single entity that enables it to sense and respond to its environment
    4. Rationality is the capacity to take the best possible decision in a given (potentially uncertain) context
    5. Logical reasoning is the capacity to respond to a stimulus or take a decision based on reproducible laws (not right, its more about creating new facts derived from proved older facts that are logically proved as well)
2. Read Turing‚Äôs original paper on AI¬†[Turing:1950](https://aimacode.github.io/aima-exercises/intro-exercises/). In the paper, he discusses several objections to his proposed enterprise and his test for intelligence. Which objections still carry weight? Are his refutations valid? Can you think of new objections arising from developments since he wrote the paper? In the paper, he predicts that, by the year 2000, a computer will have a 30% chance of passing a five-minute Turing Test with an unskilled interrogator. What chance do you think a computer would have today? In another 50 years?
    1. Objection 1: Theological ‚Äî I don‚Äôt think the value of this argument has changed in 74 years. I am far from versed in theology, but I don‚Äôt believe in immortal souls etc. I also don‚Äôt see what are the arguments to state that humans have souls but not animals, *esp* taking into account more eastern view on spirituality. Would a mechanical body be less adequate to host a soul than a fleshy one? Maybe, maybe not, who knows. My main issue with this objection is that it is based on beliefs, which don‚Äôt provide a solid basis for logical arguments.
    2. Objection 2: Head in the sand ‚Äî This argument has been used a lot regarding the debates around the consciousness of LLMs (mainly between 2022 and 2023). While I don‚Äôt think LLMs are close to consciousness in any way, shape or form, I also find that many commentators completely refuted the idea of artificial super-intelligence on the basis of a felt human superiority. I can understand that this refutal could have been used to focus on current AI issues instead of debates around robots‚Äô rights. However, I don‚Äôt think it is a legitimate refutal either.
    3. Objection 3: Mathematical ‚Äî I am not perfectly sure G√∂del‚Äôs theorem applies perfectly to the Imitation Game. Machine learning approaches have delivered solid results especially in the domain of NLP. While scalability of LLMs to other task or to reasoning (or even the ability of bigger model to solve their current issues such as hallucinations) is an active area of research, I don‚Äôt think it‚Äôs linked. I also believe that humans can indeed be wrong, so machines being wrong is not an objection to machine intelligence in my opinion.
    4. Objection 4: the Argument from Consciousness ‚Äî The hardest to decide on so far, but also the most discussed today. The *viva voce* is a very interesting approach to keep the Imitation Game relevant. However, LLMs have been showed to be able to explain poetry and emotions simply based on their training data. A difference between LLMs and a parrot-fashion learned poem is the capacity of a human to actually reason over the arguments offered during the discussion, while LLMs would probably simply repeat the same things in a loop.
    5. Objection 5: Various Disabilities ‚Äî The list of things AI can‚Äôt do has moved around a lot in the last decades. I think it is both a reflection of our refusal to ever acknowledge a machine as our equal, and of our better understanding of what makes human intelligence what it is. In that sense, AI is a fantastic tool to understand ourselves (mostly our brains) better. 
        1. Interesting thought about machine that would fix their own code (does adjusting weights count?). The fact machines don‚Äôt make mistakes is also quite not right anymore with DL. 
    6. Objection 6: Lady Lovelace‚Äôs ‚Äî The inability to learn or create anything new is also vividly discussed currently. is AI-generated art new? Is art by a debuting artist taking heavy inspiration from masters‚Äô work new? I would consider them different forms of art. I would also say that features detected and used by e.g. CV models, or strategies used by AlphaGo are definitely new and different from what humans do.
    7. Objection 7: Continuity in the Nervous System ‚Äî Probabilities indeed some form of continuity in machines, eg activation functions in NN. I also don‚Äôt believe machine intelligence will necessarily come from respecting every law governing the human brain (planes don‚Äôt flap their wings‚Ä¶).
    8. Objectif 8: Informality of Behavior ‚Äî Indeed, events not taken into account during training still are one of the biggest problems in AI/ML (self-driving cars and unplanned circumstances, LLMs can‚Äôt use tokens that don‚Äôt exist in their training corpus, etc). 
    9. Objection 9: Extra-Sensory Perception ‚Äî ü§®
    10. I believe that today, most humans (that speak a language ‚Äúknown‚Äù by LLMs) could be fooled by large language models. The examples are numerous, from Blake Lemoine to Replika users. I have no idea how to estimate the numbers however and have no idea how such feat is done.
3. Every year the Loebner Prize is awarded to the program that comes closest to passing a version of the¬†[Turing Test](https://en.wikipedia.org/wiki/Turing_test). Research and report on the latest winner of the Loebner prize. What techniques does it use? How does it advance the state of the art in AI?
    1. Seems like it hasn‚Äôt happened since 2019. It also focused heavily on chatbots in the last editions, which makes sense considering what was discussed above regarding LLMs and Turing‚Äôs test. It seems to me that (like for Asimov), the impact that the Internet would have on us was almost impossible to predict in the early second part of the XXth century. Indeed, LLMs didn‚Äôt really master human language and emotions (or, as Turing wrote, mastered English as a reasoning machine). Instead, the simply absurd amount of training data (publicly) available there and the huge advances in computing power enabled us to cheat the Turing test, making it way less obvious as an adequate test for intelligence today. I don‚Äôt know what the equivalent would be today, but that seems interesting to research. Google ‚Üí ‚ÄúWhat is the new best test for artificial intelligence?‚Äù
4. Are reflex actions (such as flinching from a hot stove) rational? Are they intelligent?
    1. They are rational because thinking and reflecting would be inadequate and lead to a undesirable outcome. They is intelligent if we define intelligence as acting rationally. It isn‚Äôt if we define intelligence as knowledge and reasoning based.
5. There are well-known classes of problems that are intractably difficult for computers, and other classes that are provably undecidable. Does this mean that AI is impossible?
    1. No. I would say that agents with the capacity to be unsure can be defined as intelligent. Indeed, if we take into account to fact that AI always compared to human intelligence, we can see that some problems are unsolvable for some people. That doesn‚Äôt mean they are not intelligent. 
6. Suppose we extend Evans‚Äôs¬†*SYSTEM*¬†program so that it can score 200 on a standard IQ test. Would we then have a program more intelligent than a human? Explain.
    1. I suppose that this is the system we are talking about? Quote from the manual: ‚ÄúTom Evans‚Äôs ANALOGY program (1968) solved geometric analogy problems that appear in IQ tests.‚Äù
    2. I would say not simply for the fact that I don‚Äôt recognize IQ as a correct assessment of human intelligence (It is linked to multiple issues and wrong measurements). Also, very much like a program, a human could prepare for these exercises to score higher (an AI could be trained specifically for the test and not do good in any other measure of intelligence). 
7. The neural structure of the sea slug¬†*Aplysis*¬†has been widely studied (first by Nobel Laureate Eric Kandel) because it has only about 20,000 neurons, most of them large and easily manipulated. Assuming that the cycle time for an¬†*Aplysis*¬†neuron is roughly the same as for a human neuron, how does the computational power, in terms of memory updates per second, compare with the high-end computer described in (Figure¬†[1.3](https://aimacode.github.io/aima-exercises/figures/computer-brain-table.png))?
8. How could introspection‚Äîreporting on one‚Äôs inner thoughts‚Äîbe inaccurate? Could I be wrong about what I‚Äôm thinking? Discuss.
    1. Not inaccurate but more incomplete, and that incompleteness can lead to inaccurate conclusions. 
9. To what extent are the following computer systems instances of artificial intelligence:
- Supermarket bar code scanners.
- Web search engines.
- Voice-activated telephone menus.
- Internet routing algorithms that respond dynamically to the state of the network.
    1. Computer vision is a well known field of AI. It is an instance of AI in the sense that it is replicating something we humans use to interact with our environment and take appropriate actions in response to it. The fact that the code is linked to a specific item is not intelligence (afaik) but simple correspondance using a mapping system and codes.
    2. The systems are examples of recommender systems. They are able to use your search data (previous inputs) to provide results more fitting to your preferences (at least this is the sales pitch). In this case, the system uses clustering to recommend results that people with the same preferences happened to find fitting. A lot more can be described as using intelligence as well, for example the spelling errors recognition.
    3. Speech recognition is comparable to computer vision because it is also emulating a human sense. In this case, the system is able to link what you are outputting and link it to a predefined item in a menu.
    4. Not sure about this one. Finding the best route in a changing environment shows adaptability.
10. /
11. Many of the computational models of cognitive activities that have been proposed involve quite complex mathematical operations, such as convolving an image with a Gaussian or finding a minimum of the entropy function. Most humans (and certainly all animals) never learn this kind of mathematics at all, almost no one learns it before college, and almost no one can compute the convolution of a function with a Gaussian in their head. What sense does it make to say that the ‚Äúvision system‚Äù is doing this kind of mathematics, whereas the actual person has no idea how to do it?
    1. We do a whole lot of things without knowing/understanding how it works. I‚Äôm pretty sure no one can map the entire neural influxes needed to have any thought whatsoever. Some things happen following mathematical rules that cannot be understood by the majority of humans, even less so computed.
12. Some authors have claimed that perception and motor skills are the most important part of intelligence, and that ‚Äúhigher level‚Äù capacities are necessarily parasitic‚Äîsimple add-ons to these underlying facilities. Certainly, most of evolution and a large part of the brain have been devoted to perception and motor skills, whereas AI has found tasks such as game playing and logical inference to be easier, in many ways, than perceiving and acting in the real world. Do you think that AI‚Äôs traditional focus on higher-level cognitive abilities is misplaced?
    1. I wouldn‚Äôt say it‚Äôs misplaced. Motor skills for example are difficult to test in the real world because of the faster evolution of software compared to hardware. It‚Äôs also notoriously difficult to adapt AI to the real world because of the many, many edge cases present. Autonomous cars are a good example of that. We often try to have agents that can perform well in any environment, where animals and humans are traditionally adapted to a specific one. Also, the focus on games comes from this idea of an ideal world in which the rules are clear and unchanged. The traditional direction from games to simulations to the real world makes sense in that way. 
13. Why would evolution tend to result in systems that act rationally? What goals are such systems designed to achieve?
    1. Because evolution selects the most fitted individuals (agents?) in a given environment. Being rational is simply maximizing the performance, so is aligned with this idea. 
14. Is AI a science, or is it engineering? Or neither or both? Explain.
    1. AI is a field of science that is coming from and influenced by a lot of other domains, among which engineering. To build on the LLM example, the text embeddings and vectorial representations take a lot from linguistics, where improvements in computation power comes from engineering.
15. ‚ÄúSurely computers cannot be intelligent‚Äîthey can do only what their programmers tell them.‚Äù Is the latter statement true, and does it imply the former?
    1. It is, in a sense, true. While AI programmers don‚Äôt explicitly code the different aspects of the agents, they define their utility functions and performance measure. However, agents can, and often do, act in creative and novel ways to follow these rules in a way that the programmers didn‚Äôt anticipate.
16. ‚ÄúSurely animals cannot be intelligent‚Äîthey can do only what their genes tell them.‚Äù Is the latter statement true, and does it imply the former?
    1. I would say that in this case, because the mechanism is different in my opinion, it is untrue. Genes are what enable intelligent behavior to arise. Where this distinction comes from is more difficult to know for me, but I think it has to do with the fact that the intelligence animals display is not coming from humans maybe. Also, genes don‚Äôt give you all the information you need, you learn with experience and experiments in the real world. Something AI cannot do (yet).  
17. ‚ÄúSurely animals, humans, and computers cannot be intelligent‚Äîthey can do only what their constituent atoms are told to do by the laws of physics.‚Äù Is the latter statement true, and does it imply the former?
    1. Same argument than above but stronger; laws of physics are not much help when deciding what food to order (tbh that doesn‚Äôt sound like a good punchline, not even a good argument‚Ä¶).
18. Examine the AI literature to discover whether the following tasks can currently be solved by computers: - Playing a decent game of table tennis (Ping-Pong). - Driving in the center of Cairo, Egypt. - Driving in Victorville, California. - Buying a week‚Äôs worth of groceries at the market. - Buying a week‚Äôs worth of groceries on the Web. - Playing a decent game of bridge at a competitive level. - Discovering and proving new mathematical theorems. - Writing an intentionally funny story. - Giving competent legal advice in a specialized area of law. - Translating spoken English into spoken Swedish in real time. - Performing a complex surgical operation.
    1. https://spectrum.ieee.org/robots-playing-ping-pong-whats-real-and-whats-not
    2. https://waymo.com/ ‚Äî It‚Äôs possible in SF, should be in Cairo given sufficient training data (though I must admit I don‚Äôt know how the traffic is there). Should be easier in California.
    3. In the market no, no robot functions at that level of real-world interaction yet.
    4. LLM agent should be able to do it if we believe the AI gurus (see Rabbit R1). It should be easy to do if the grocery list and supermarket are determined in advance, and if the supermarket has a good API.
    5. [https://www.quora.com/Can-AI-play-perfect-Bridge#:~:text=Yes%2C computer bridge programs play,plays%2C but it's all inferential](https://www.quora.com/Can-AI-play-perfect-Bridge#:~:text=Yes%2C%20computer%20bridge%20programs%20play,plays%2C%20but%20it's%20all%20inferential)
    6. [https://en.wikipedia.org/wiki/Automated_theorem_proving#:~:text=Interactive provers are used for,time%2C namely the Robbins conjecture](https://en.wikipedia.org/wiki/Automated_theorem_proving#:~:text=Interactive%20provers%20are%20used%20for,time%2C%20namely%20the%20Robbins%20conjecture).
    7. Yes (or no, depending on the definition of intentionality).
    8. Yes (if you don‚Äôt take into account hallucinations).
    9. Yes.
    10. https://www.cureus.com/articles/204683-future-of-artificial-intelligence-in-surgery-a-narrative-review#!/
19. For the currently infeasible tasks, try to find out what the difficulties are and predict when, if ever, they will be overcome.
    1. A lot of issues have to do with hardware limitations (real world interactions) or lack of data. I believe they could be solved in the next 5 to 10 years.
20. Various subfields of AI have held contests by defining a standard task and inviting researchers to do their best. Examples include the DARPA Grand Challenge for robotic cars, the International Planning Competition, the Robocup robotic soccer league, the TREC information retrieval event, and contests in machine translation and speech recognition. Investigate five of these contests and describe the progress made over the years. To what degree have the contests advanced the state of the art in AI? To what degree do they hurt the field by drawing energy away from new ideas?
    1. https://en.wikipedia.org/wiki/DARPA_Grand_Challenge
    2. https://www.icaps-conference.org/competitions/
    3. https://www.robocup.org/leagues/18
    4. https://trec.nist.gov/
    5. https://www.nist.gov/programs-projects/machine-translation